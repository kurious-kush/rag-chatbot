{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXv58-_ahULD",
        "outputId": "7c0e956f-c296-43b9-8f72-cd31b4d7737f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.17)\n",
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: cassio in /usr/local/lib/python3.10/dist-packages (0.1.7)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.34.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.37)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.52)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.54)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.5.2)\n",
            "Requirement already satisfied: cassandra-driver<4.0.0,>=3.28.0 in /usr/local/lib/python3.10/dist-packages (from cassio) (3.29.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.11.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: geomet<0.3,>=0.1 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver<4.0.0,>=3.28.0->cassio) (0.2.1.post1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.2 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (0.6.2)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (2.27.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (4.66.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.2->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (1.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver<4.0.0,>=3.28.0->cassio) (1.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (4.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (1.63.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (1.63.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (0.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain_google_genai cassio streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fmnSAvqiUX_",
        "outputId": "973c83e1-648a-4145-cfd0-c737160f288e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.17)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.37)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.52)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.54)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.48->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11m8nBhukMOg",
        "outputId": "0e21a9ab-bca0-4242-fe30-477aa6639b6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting astrapy\n",
            "  Downloading astrapy-1.1.0-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m124.4/124.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bson<0.6.0,>=0.5.10 (from astrapy)\n",
            "  Downloading bson-0.5.10.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cassio<0.2.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from astrapy) (0.1.7)\n",
            "Collecting deprecation<2.2.0,>=2.1.0 (from astrapy)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting httpx[http2]<1,>=0.25.2 (from astrapy)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: toml<0.11.0,>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from astrapy) (0.10.2)\n",
            "Collecting uuid6<2024.2.0,>=2024.1.12 (from astrapy)\n",
            "  Downloading uuid6-2024.1.12-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from bson<0.6.0,>=0.5.10->astrapy) (2.8.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bson<0.6.0,>=0.5.10->astrapy) (1.16.0)\n",
            "Requirement already satisfied: cassandra-driver<4.0.0,>=3.28.0 in /usr/local/lib/python3.10/dist-packages (from cassio<0.2.0,>=0.1.4->astrapy) (3.29.1)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from cassio<0.2.0,>=0.1.4->astrapy) (1.25.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from cassio<0.2.0,>=0.1.4->astrapy) (2.31.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from deprecation<2.2.0,>=2.1.0->astrapy) (23.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx[http2]<1,>=0.25.2->astrapy) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx[http2]<1,>=0.25.2->astrapy) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx[http2]<1,>=0.25.2->astrapy)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx[http2]<1,>=0.25.2->astrapy) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx[http2]<1,>=0.25.2->astrapy) (1.3.1)\n",
            "Collecting h2<5,>=3 (from httpx[http2]<1,>=0.25.2->astrapy)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx[http2]<1,>=0.25.2->astrapy)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: geomet<0.3,>=0.1 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver<4.0.0,>=3.28.0->cassio<0.2.0,>=0.1.4->astrapy) (0.2.1.post1)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]<1,>=0.25.2->astrapy)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]<1,>=0.25.2->astrapy)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->cassio<0.2.0,>=0.1.4->astrapy) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->cassio<0.2.0,>=0.1.4->astrapy) (2.0.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx[http2]<1,>=0.25.2->astrapy) (1.2.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver<4.0.0,>=3.28.0->cassio<0.2.0,>=0.1.4->astrapy) (8.1.7)\n",
            "Building wheels for collected packages: bson\n",
            "  Building wheel for bson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bson: filename=bson-0.5.10-py3-none-any.whl size=11976 sha256=6f6759fc3c213dd3e0ca69b13524a1c45e0687f1578616a25814731c4af707f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/49/3b/8b33954dfae7a176009c4d721a45af56c8a9c1cdc3ee947945\n",
            "Successfully built bson\n",
            "Installing collected packages: uuid6, hyperframe, hpack, h11, deprecation, httpcore, h2, bson, httpx, astrapy\n",
            "Successfully installed astrapy-1.1.0 bson-0.5.10 deprecation-2.1.0 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.5 httpx-0.27.0 hyperframe-6.0.1 uuid6-2024.1.12\n"
          ]
        }
      ],
      "source": [
        "pip install astrapy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sh7ub9wtog9R"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set your Google API key here\n",
        "GOOGLE_API_KEY = \"AIzaSyBpZJYfrHuVqcWG5WaTXQ_-vOKMc3FIRPc\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyFcWkEqiD4w",
        "outputId": "79471a2f-fdf6-4737-b055-b3a8224468c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected to Astra DB: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-06 23:04:32.723 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2024-05-06 23:04:32.725 Session state does not function when running a script without `streamlit run`\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import time\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "import os\n",
        "import cassio\n",
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.embeddings import GooglePalmEmbeddings\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "\n",
        "# Set your Google API key here\n",
        "GOOGLE_API_KEY = GOOGLE_API_KEY\n",
        "\n",
        "# Provide Astra DB connection details\n",
        "ASTRA_DB_APPLICATION_TOKEN = \"AstraCS:LfvQnAQHwfAThhucwFQsCfSf:9ce730d740d699dbb1213b5bf88a8680457263237f9e1c85dcf5ec54947c8c2d\"\n",
        "ASTRA_DB_ID = \"86538be5-7d9d-4c2a-9843-e8560b179d01\"\n",
        "\n",
        "from astrapy import DataAPIClient\n",
        "\n",
        "# Initialize the client\n",
        "client = DataAPIClient(ASTRA_DB_APPLICATION_TOKEN)\n",
        "db = client.get_database_by_api_endpoint(\n",
        "  \"https://86538be5-7d9d-4c2a-9843-e8560b179d01-us-east1.apps.astra.datastax.com\"\n",
        ")\n",
        "\n",
        "print(f\"Connected to Astra DB: {db.list_collection_names()}\")\n",
        "def process_pdf(pdf_path):\n",
        "    # Implement PDF processing logic using your preferred method\n",
        "    pass\n",
        "\n",
        "def chunk_text(text):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    return chunks\n",
        "\n",
        "def user_input(question, google_api_key):\n",
        "    # Load Astra DB vector store\n",
        "    cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)\n",
        "    astra_vector_store = Cassandra(\n",
        "        embedding=GooglePalmEmbeddings(model=\"models/embedding-001\", google_api_key=google_api_key),\n",
        "        table_name=\"your_table_name\"\n",
        "    )\n",
        "\n",
        "    # Search for similar documents\n",
        "    docs = astra_vector_store.similarity_search(question)\n",
        "\n",
        "    # Initialize conversational chain\n",
        "    model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3, google_api_key=google_api_key)\n",
        "    prompt_template = \"\"\"\n",
        "    Answer the question as detailed as possible from the provided context, make sure to provide all the details, if the answer is not in\n",
        "    provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n",
        "    Context:\\n {context}?\\n\n",
        "    Question: \\n{question}\\n\n",
        "\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "    chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
        "\n",
        "    # Generate response\n",
        "    response = chain({\"input_documents\": docs, \"question\": question}, return_only_outputs=True)\n",
        "    return response[\"output_text\"]\n",
        "\n",
        "def main():\n",
        "    # Set the page configuration as the first Streamlit command\n",
        "    st.set_page_config(page_title=\"Chat PDF\", layout=\"wide\")\n",
        "\n",
        "    # Custom CSS for background color and animation\n",
        "    main_bg = \"#f0f0f0\"\n",
        "    main_bg_color = f\"background-color: {main_bg};\"\n",
        "    st.markdown(\n",
        "        f\"\"\"\n",
        "        <style>\n",
        "            .reportview-container .main .block-container{{\n",
        "                {main_bg_color}\n",
        "            }}\n",
        "        </style>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "\n",
        "    st.header(\"AHOY!:) I am GeminiüíÅ lets take RAG to next level\")\n",
        "    user_question = st.text_input(\"Ask any Question from the PDF Files\")\n",
        "\n",
        "    if user_question:\n",
        "        st.write(\"You:\", user_question)\n",
        "        st.write(\"Gemini:\", \"Thinking...\")\n",
        "\n",
        "        with st.spinner(\"Gemini is thinking...\"):\n",
        "            time.sleep(3)  # Simulating processing time\n",
        "\n",
        "            # Generate response\n",
        "            response = user_input(user_question, GOOGLE_API_KEY)\n",
        "\n",
        "            st.write(\"Gemini:\", response)\n",
        "\n",
        "    with st.sidebar:\n",
        "        st.title(\"Menu:\")\n",
        "        pdf_docs = st.file_uploader(\"Upload your PDF Files and Click on the Submit & Process Button\", accept_multiple_files=True)\n",
        "        if st.button(\"Submit & Process\"):\n",
        "            with st.spinner(\"Processing...\"):\n",
        "                # Process PDF files and add text chunks to Astra DB\n",
        "                for pdf_file in pdf_docs:\n",
        "                    raw_text = process_pdf(pdf_file)\n",
        "                    text_chunks = chunk_text(raw_text)\n",
        "                    # Add text chunks to Astra DB vector store\n",
        "                    cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)\n",
        "                    astra_vector_store = Cassandra(\n",
        "                        embedding=GooglePalmEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEY),\n",
        "                        table_name=\"your_table_name\"\n",
        "                    )\n",
        "                    astra_vector_store.add_texts(text_chunks)\n",
        "                st.success(\"Done\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eAI_NvcnMcI",
        "outputId": "a1e6786c-dfea-438e-d7a5-d80fc8818bc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.5.0-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/75.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.0/75.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.18.2)\n",
            "Installing collected packages: groq\n",
            "Successfully installed groq-0.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCmrHqQ_o2Qp"
      },
      "outputs": [],
      "source": [
        "!pip install -q groq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIoeBPJSnJC6"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import time\n",
        "from groq import Groq  # Import Groq\n",
        "\n",
        "# Set your Groq API key here\n",
        "GROQ_API_KEY = \"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\"\n",
        "GOOGLE_API_KEY = \"AIzaSyBpZJYfrHuVqcWG5WaTXQ_-vOKMc3FIRPc\"\n",
        "ASTRA_DB_APPLICATION_TOKEN = \"AstraCS:LfvQnAQHwfAThhucwFQsCfSf:9ce730d740d699dbb1213b5bf88a8680457263237f9e1c85dcf5ec54947c8c2d\"\n",
        "ASTRA_DB_ID = \"86538be5-7d9d-4c2a-9843-e8560b179d01\"\n",
        "\n",
        "# Import your existing code\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "import os\n",
        "import cassio\n",
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.embeddings import GooglePalmEmbeddings\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from astrapy import DataAPIClient\n",
        "\n",
        "def process_pdf(pdf_path):\n",
        "    # Implement PDF processing logic using your preferred method\n",
        "    pass\n",
        "\n",
        "def chunk_text(text):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    return chunks\n",
        "\n",
        "def add_pdf_to_db(pdf_docs):\n",
        "    # Process PDF files and add text chunks to Astra DB\n",
        "    for pdf_file in pdf_docs:\n",
        "        raw_text = process_pdf(pdf_file)\n",
        "        text_chunks = chunk_text(raw_text)\n",
        "        # Add text chunks to Astra DB vector store\n",
        "        cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)\n",
        "        astra_vector_store = Cassandra(\n",
        "            embedding=GooglePalmEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEY),\n",
        "            table_name=\"your_table_name\"\n",
        "        )\n",
        "        astra_vector_store.add_texts(text_chunks)\n",
        "\n",
        "def user_input(question, google_api_key, model_type):\n",
        "    if model_type == \"Gemini\":\n",
        "        # Load Astra DB vector store\n",
        "        cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)\n",
        "        astra_vector_store = Cassandra(\n",
        "            embedding=GooglePalmEmbeddings(model=\"models/embedding-001\", google_api_key=google_api_key),\n",
        "            table_name=\"your_table_name\"\n",
        "        )\n",
        "\n",
        "        # Search for similar documents\n",
        "        docs = astra_vector_store.similarity_search(question)\n",
        "\n",
        "        # Initialize conversational chain\n",
        "        model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3, google_api_key=google_api_key)\n",
        "        prompt_template = \"\"\"\n",
        "        Answer the question as detailed as possible from the provided context, make sure to provide all the details, if the answer is not in\n",
        "        provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n",
        "        Context:\\n {context}?\\n\n",
        "        Question: \\n{question}\\n\n",
        "\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "        chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
        "\n",
        "        # Generate response\n",
        "        response = chain({\"input_documents\": docs, \"question\": question}, return_only_outputs=True)\n",
        "        return response[\"output_text\"]\n",
        "    elif model_type == \"Groq\":\n",
        "        # Initialize Groq model with your API key\n",
        "        client = Groq(api_key=GROQ_API_KEY)\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": question,\n",
        "                }\n",
        "            ],\n",
        "            model=\"llama3-70b-8192\",\n",
        "        )\n",
        "        return chat_completion.choices[0].message.content\n",
        "\n",
        "def main():\n",
        "    # Set the page configuration as the first Streamlit command\n",
        "    st.set_page_config(page_title=\"Chat PDF\", layout=\"wide\")\n",
        "\n",
        "    # Custom CSS for background color and animation\n",
        "    main_bg = \"#f0f0f0\"\n",
        "    main_bg_color = f\"background-color: {main_bg};\"\n",
        "    st.markdown(\n",
        "        f\"\"\"\n",
        "        <style>\n",
        "            .reportview-container .main .block-container{{\n",
        "                {main_bg_color}\n",
        "            }}\n",
        "        </style>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "\n",
        "    st.header(\"AHOY!:) I am GeminiüíÅ lets take RAG to next level\")\n",
        "    user_question = st.text_input(\"Ask any Question from the PDF Files\")\n",
        "\n",
        "    # Add a selectbox for choosing the model type\n",
        "    model_type = st.selectbox(\"Select Chat Model\", (\"Gemini\", \"Groq\"))\n",
        "\n",
        "    if user_question:\n",
        "        st.write(\"You:\", user_question)\n",
        "        st.write(model_type + \":\", \"Thinking...\")\n",
        "\n",
        "        with st.spinner(model_type + \" is thinking...\"):\n",
        "            time.sleep(3)  # Simulating processing time\n",
        "\n",
        "            # Generate response\n",
        "            response = user_input(user_question, GOOGLE_API_KEY, model_type)\n",
        "\n",
        "            st.write(model_type + \":\", response)\n",
        "\n",
        "    with st.sidebar:\n",
        "        st.title(\"Menu:\")\n",
        "        pdf_docs = st.file_uploader(\"Upload your PDF Files and Click on the Submit & Process Button\", accept_multiple_files=True)\n",
        "        if st.button(\"Submit & Process\"):\n",
        "            with st.spinner(\"Processing...\"):\n",
        "                # Add uploaded PDF files to Astra DB\n",
        "                add_pdf_to_db(pdf_docs)\n",
        "                st.success(\"PDFs added to Astra DB\")\n",
        "\n",
        "    # Render a different layout for Groq chat\n",
        "    if model_type == \"Groq\":\n",
        "        st.title(\"Chat with Groq Have fun!!!!\")\n",
        "        groq_question = st.text_input(\"Ask any question\")\n",
        "        if st.button(\"Ask\"):\n",
        "            if groq_question:\n",
        "                with st.spinner(\"Thinking...\"):\n",
        "                    time.sleep(2)\n",
        "                    response = user_input(groq_question, GOOGLE_API_KEY, model_type)\n",
        "                    st.write(\"Groq:\", response)\n",
        "\n",
        "        # Add suggested prompts as buttons\n",
        "        st.subheader(\"Suggested Prompts:\")\n",
        "        groq_prompts = [\n",
        "            \"Do you know what's LPU and how Groq works?\",\n",
        "            \"What is fast inferencing in LPU?\",\n",
        "            \"LPU vs GPU\",\n",
        "            \"How fast is Groq compared to Gemini?\"\n",
        "        ]\n",
        "        for prompt in groq_prompts:\n",
        "            if st.button(prompt):\n",
        "                with st.spinner(\"Thinking...\"):\n",
        "                    time.sleep(2)\n",
        "                    response = user_input(prompt, GOOGLE_API_KEY, model_type)\n",
        "                    st.write(\"Groq:\", response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2GNNFKLrk2Z"
      },
      "outputs": [],
      "source": [
        "GROQ_API_KEY = \"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\"\n",
        "GOOGLE_API_KEY = \"AIzaSyBpZJYfrHuVqcWG5WaTXQ_-vOKMc3FIRPc\"\n",
        "ASTRA_DB_APPLICATION_TOKEN = \"AstraCS:LfvQnAQHwfAThhucwFQsCfSf:9ce730d740d699dbb1213b5bf88a8680457263237f9e1c85dcf5ec54947c8c2d\"\n",
        "ASTRA_DB_ID = \"86538be5-7d9d-4c2a-9843-e8560b179d01\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt2wqLU-2pKs",
        "outputId": "3196a51f-cec9-4557-d706-9688470fddfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading PyMuPDF-1.24.2-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.24.1 (from pymupdf)\n",
            "  Downloading PyMuPDFb-1.24.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, pymupdf\n",
            "Successfully installed PyMuPDFb-1.24.1 pymupdf-1.24.2\n"
          ]
        }
      ],
      "source": [
        "pip install pymupdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDvL_k2Wrbd5",
        "outputId": "692e8b4b-eb8d-498e-d92c-63d512bc6d75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected to Astra DB: []\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import time\n",
        "from groq import Groq  # Import Groq\n",
        "\n",
        "# Set your Groq API key here\n",
        "GROQ_API_KEY = \"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\"\n",
        "\n",
        "# Import your existing code\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "import os\n",
        "import cassio\n",
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.embeddings import GooglePalmEmbeddings\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from astrapy import DataAPIClient\n",
        "\n",
        "# Set your Google API key here\n",
        "GOOGLE_API_KEY = \"AIzaSyBpZJYfrHuVqcWG5WaTXQ_-vOKMc3FIRPc\"\n",
        "\n",
        "# Provide Astra DB connection details\n",
        "ASTRA_DB_APPLICATION_TOKEN = \"AstraCS:LfvQnAQHwfAThhucwFQsCfSf:9ce730d740d699dbb1213b5bf88a8680457263237f9e1c85dcf5ec54947c8c2d\"\n",
        "ASTRA_DB_ID = \"86538be5-7d9d-4c2a-9843-e8560b179d01\"\n",
        "\n",
        "# Initialize the client\n",
        "client = DataAPIClient(ASTRA_DB_APPLICATION_TOKEN)\n",
        "db = client.get_database_by_api_endpoint(\n",
        "  \"https://86538be5-7d9d-4c2a-9843-e8560b179d01-us-east1.apps.astra.datastax.com\"\n",
        ")\n",
        "\n",
        "print(f\"Connected to Astra DB: {db.list_collection_names()}\")\n",
        "\n",
        "\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "def process_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        # Open the PDF file\n",
        "        with fitz.open(pdf_path) as doc:\n",
        "            # Extract text from each page\n",
        "            for page in doc:\n",
        "                text += page.get_text()\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing PDF: {e}\")\n",
        "    return text\n",
        "\n",
        "    pass\n",
        "\n",
        "def chunk_text(text):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    return chunks\n",
        "\n",
        "def add_pdf_to_db(pdf_docs):\n",
        "    # Process PDF files and add text chunks to Astra DB\n",
        "    for pdf_file in pdf_docs:\n",
        "        raw_text = process_pdf(pdf_file)\n",
        "        text_chunks = chunk_text(raw_text)\n",
        "        # Add text chunks to Astra DB vector store\n",
        "        cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)\n",
        "        astra_vector_store = Cassandra(\n",
        "            embedding=GooglePalmEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEY),\n",
        "            table_name=\"your_table_name\"\n",
        "        )\n",
        "        astra_vector_store.add_texts(text_chunks)\n",
        "\n",
        "def user_input(question, google_api_key, model_type):\n",
        "    if model_type == \"Gemini\":\n",
        "        # Load Astra DB vector store\n",
        "        cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)\n",
        "        astra_vector_store = Cassandra(\n",
        "            embedding=GooglePalmEmbeddings(model=\"models/embedding-001\", google_api_key=google_api_key),\n",
        "            table_name=\"your_table_name\"\n",
        "        )\n",
        "\n",
        "        # Search for similar documents\n",
        "        docs = astra_vector_store.similarity_search(question)\n",
        "\n",
        "        # Initialize conversational chain\n",
        "        model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3, google_api_key=google_api_key)\n",
        "        prompt_template = \"\"\"\n",
        "        Answer the question as detailed as possible from the provided context, make sure to provide all the details, if the answer is not in\n",
        "        provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n",
        "        Context:\\n {context}?\\n\n",
        "        Question: \\n{question}\\n\n",
        "\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "        chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
        "\n",
        "        # Generate response\n",
        "        response = chain({\"input_documents\": docs, \"question\": question}, return_only_outputs=True)\n",
        "        return response[\"output_text\"]\n",
        "    elif model_type == \"Groq\":\n",
        "        # Initialize Groq model with your API key\n",
        "        client = Groq(api_key=GROQ_API_KEY)\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": question,\n",
        "                }\n",
        "            ],\n",
        "            model=\"llama3-70b-8192\",\n",
        "        )\n",
        "        return chat_completion.choices[0].message.content\n",
        "\n",
        "def main():\n",
        "    # Set the page configuration as the first Streamlit command\n",
        "    st.set_page_config(page_title=\"Chat PDF\", layout=\"wide\")\n",
        "\n",
        "    # Custom CSS for background color and animation\n",
        "    main_bg = \"#f0f0f0\"\n",
        "    main_bg_color = f\"background-color: {main_bg};\"\n",
        "    st.markdown(\n",
        "        f\"\"\"\n",
        "        <style>\n",
        "            .reportview-container .main .block-container{{\n",
        "                {main_bg_color}\n",
        "            }}\n",
        "        </style>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "\n",
        "    st.header(\"AHOY!:) I am GeminiüíÅ lets take RAG to next level\")\n",
        "    user_question = st.text_input(\"Ask any Question from the PDF Files\")\n",
        "\n",
        "    # Add a selectbox for choosing the model type\n",
        "    model_type = st.selectbox(\"Select Chat Model\", (\"Gemini\", \"Groq\"))\n",
        "\n",
        "    if user_question:\n",
        "        st.write(\"You:\", user_question)\n",
        "        st.write(model_type + \":\", \"Thinking...\")\n",
        "\n",
        "        with st.spinner(model_type + \" is thinking...\"):\n",
        "            time.sleep(3)  # Simulating processing time\n",
        "\n",
        "            # Generate response\n",
        "            response = user_input(user_question, GOOGLE_API_KEY, model_type)\n",
        "\n",
        "            st.write(model_type + \":\", response)\n",
        "\n",
        "    with st.sidebar:\n",
        "        st.title(\"Menu:\")\n",
        "        pdf_docs = st.file_uploader(\"Upload your PDF Files and Click on the Submit & Process Button\", accept_multiple_files=True)\n",
        "        if st.button(\"Submit & Process\"):\n",
        "            with st.spinner(\"Processing...\"):\n",
        "                # Add uploaded PDF files to Astra DB\n",
        "                add_pdf_to_db(pdf_docs)\n",
        "                st.success(\"PDFs added to Astra DB\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i9SNsyyiKxX",
        "outputId": "84fb17e9-aa68-4402-97d2-6998332c57b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "104.198.235.124\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://104.198.235.124:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 6.826s\n",
            "your url is: https://mean-flies-buy.loca.lt\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/_api/module_import.py:87: LangChainDeprecationWarning: Importing GuardrailsOutputParser from langchain.output_parsers is deprecated. Please replace the import with the following:\n",
            "from langchain_community.output_parsers.rail_parser import GuardrailsOutputParser\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/embeddings/__init__.py:29: LangChainDeprecationWarning: Importing embeddings from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.embeddings import GooglePalmEmbeddings`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "Connected to Astra DB: []\n",
            "Connected to Astra DB: []\n",
            "Connected to Astra DB: []\n",
            "Connected to Astra DB: []\n",
            "Error processing PDF: no such file: 'NMDS PCA ENHANCE.pdf'\n",
            "Connected to Astra DB: []\n",
            "Connected to Astra DB: []\n",
            "Connected to Astra DB: []\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/embeddings/__init__.py:29: LangChainDeprecationWarning: Importing embeddings from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.embeddings import GooglePalmEmbeddings`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "Connected to Astra DB: []\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/embeddings/__init__.py:29: LangChainDeprecationWarning: Importing embeddings from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.embeddings import GooglePalmEmbeddings`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "Connected to Astra DB: []\n",
            "Connected to Astra DB: []\n",
            "Connected to Astra DB: []\n"
          ]
        }
      ],
      "source": [
        "! pip install streamlit -q\n",
        "!wget -q -O - ipv4.icanhazip.com\n",
        "! streamlit run bd_app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E44lFUj65r9w"
      },
      "source": [
        "app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN1cn1IQ5r61"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6n9ZI9n5qRt"
      },
      "outputs": [],
      "source": [
        "# import streamlit as st\n",
        "# import time\n",
        "# from groq import Groq  # Import Groq\n",
        "\n",
        "# # Set your Groq API key here\n",
        "# GROQ_API_KEY = \"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\"\n",
        "\n",
        "# # Import your existing code\n",
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# from langchain.chains.question_answering import load_qa_chain\n",
        "# from langchain.prompts import PromptTemplate\n",
        "# import os\n",
        "# import cassio\n",
        "# from langchain.vectorstores.cassandra import Cassandra\n",
        "# from langchain.embeddings import GooglePalmEmbeddings\n",
        "# from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "# from astrapy import DataAPIClient\n",
        "\n",
        "# # Set your Google API key here\n",
        "# GOOGLE_API_KEY = \"AIzaSyBpZJYfrHuVqcWG5WaTXQ_-vOKMc3FIRPc\"\n",
        "\n",
        "# # Provide Astra DB connection details\n",
        "# ASTRA_DB_APPLICATION_TOKEN = \"AstraCS:LfvQnAQHwfAThhucwFQsCfSf:9ce730d740d699dbb1213b5bf88a8680457263237f9e1c85dcf5ec54947c8c2d\"\n",
        "# ASTRA_DB_ID = \"86538be5-7d9d-4c2a-9843-e8560b179d01\"\n",
        "\n",
        "# # Initialize the client\n",
        "# client = DataAPIClient(ASTRA_DB_APPLICATION_TOKEN)\n",
        "# db = client.get_database_by_api_endpoint(\n",
        "#   \"https://86538be5-7d9d-4c2a-9843-e8560b179d01-us-east1.apps.astra.datastax.com\"\n",
        "# )\n",
        "\n",
        "# print(f\"Connected to Astra DB: {db.list_collection_names()}\")\n",
        "\n",
        "\n",
        "# import fitz  # PyMuPDF\n",
        "\n",
        "# def process_pdf(pdf_path):\n",
        "#     text = \"\"\n",
        "#     try:\n",
        "#         # Open the PDF file\n",
        "#         with fitz.open(pdf_path) as doc:\n",
        "#             # Extract text from each page\n",
        "#             for page in doc:\n",
        "#                 text += page.get_text()\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error processing PDF: {e}\")\n",
        "#     return text\n",
        "\n",
        "#     pass\n",
        "\n",
        "# def chunk_text(text):\n",
        "#     text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n",
        "#     chunks = text_splitter.split_text(text)\n",
        "#     return chunks\n",
        "\n",
        "# def add_pdf_to_db(pdf_docs):\n",
        "#     # Process PDF files and add text chunks to Astra DB\n",
        "#     for pdf_file in pdf_docs:\n",
        "#         raw_text = process_pdf(pdf_file)\n",
        "#         text_chunks = chunk_text(raw_text)\n",
        "#         # Add text chunks to Astra DB vector store\n",
        "#         cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)\n",
        "#         astra_vector_store = Cassandra(\n",
        "#             embedding=GooglePalmEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEY),\n",
        "#             table_name=\"your_table_name\"\n",
        "#         )\n",
        "#         astra_vector_store.add_texts(text_chunks)\n",
        "\n",
        "# def user_input(question, google_api_key, model_type):\n",
        "#     if model_type == \"Gemini\":\n",
        "#         # Load Astra DB vector store\n",
        "#         cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)\n",
        "#         astra_vector_store = Cassandra(\n",
        "#             embedding=GooglePalmEmbeddings(model=\"models/embedding-001\", google_api_key=google_api_key),\n",
        "#             table_name=\"your_table_name\"\n",
        "#         )\n",
        "\n",
        "#         # Search for similar documents\n",
        "#         docs = astra_vector_store.similarity_search(question)\n",
        "\n",
        "#         # Initialize conversational chain\n",
        "#         model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3, google_api_key=google_api_key)\n",
        "#         prompt_template = \"\"\"\n",
        "#         Answer the question as detailed as possible from the provided context, make sure to provide all the details, if the answer is not in\n",
        "#         provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n",
        "#         Context:\\n {context}?\\n\n",
        "#         Question: \\n{question}\\n\n",
        "\n",
        "#         Answer:\n",
        "#         \"\"\"\n",
        "#         prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "#         chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
        "\n",
        "#         # Generate response\n",
        "#         response = chain({\"input_documents\": docs, \"question\": question}, return_only_outputs=True)\n",
        "#         return response[\"output_text\"]\n",
        "#     elif model_type == \"Groq\":\n",
        "#         # Initialize Groq model with your API key\n",
        "#         client = Groq(api_key=GROQ_API_KEY)\n",
        "#         chat_completion = client.chat.completions.create(\n",
        "#             messages=[\n",
        "#                 {\n",
        "#                     \"role\": \"user\",\n",
        "#                     \"content\": question,\n",
        "#                 }\n",
        "#             ],\n",
        "#             model=\"llama3-70b-8192\",\n",
        "#         )\n",
        "#         return chat_completion.choices[0].message.content\n",
        "\n",
        "# def main():\n",
        "#     # Set the page configuration as the first Streamlit command\n",
        "#     st.set_page_config(page_title=\"Chat PDF\", layout=\"wide\")\n",
        "\n",
        "#     # Custom CSS for background color and animation\n",
        "#     main_bg = \"#f0f0f0\"\n",
        "#     main_bg_color = f\"background-color: {main_bg};\"\n",
        "#     st.markdown(\n",
        "#         f\"\"\"\n",
        "#         <style>\n",
        "#             .reportview-container .main .block-container{{\n",
        "#                 {main_bg_color}\n",
        "#             }}\n",
        "#         </style>\n",
        "#         \"\"\",\n",
        "#         unsafe_allow_html=True\n",
        "#     )\n",
        "\n",
        "#     st.header(\"AHOY!:) I am GeminiüíÅ lets take RAG to next level\")\n",
        "#     user_question = st.text_input(\"Ask any Question from the PDF Files\")\n",
        "\n",
        "#     # Add a selectbox for choosing the model type\n",
        "#     model_type = st.selectbox(\"Select Chat Model\", (\"Gemini\", \"Groq\"))\n",
        "\n",
        "#     if user_question:\n",
        "#         st.write(\"You:\", user_question)\n",
        "#         st.write(model_type + \":\", \"Thinking...\")\n",
        "\n",
        "#         with st.spinner(model_type + \" is thinking...\"):\n",
        "#             time.sleep(3)  # Simulating processing time\n",
        "\n",
        "#             # Generate response\n",
        "#             response = user_input(user_question, GOOGLE_API_KEY, model_type)\n",
        "\n",
        "#             st.write(model_type + \":\", response)\n",
        "\n",
        "#     with st.sidebar:\n",
        "#         st.title(\"Menu:\")\n",
        "#         pdf_docs = st.file_uploader(\"Upload your PDF Files and Click on the Submit & Process Button\", accept_multiple_files=True)\n",
        "#         if st.button(\"Submit & Process\"):\n",
        "#             with st.spinner(\"Processing...\"):\n",
        "#                 # Add uploaded PDF files to Astra DB\n",
        "#                 add_pdf_to_db(pdf_docs)\n",
        "#                 st.success(\"PDFs added to Astra DB\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}